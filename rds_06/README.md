## RDS 06: Возьмёте Бэтмобиль?

Построение модели классификации изображений и участие в соотвестующем [соревновании на Kaggle](https://www.kaggle.com/c/sf-dst-car-price-prediction-part2/ "соревновании на Kaggle")

![](https://lms.skillfactory.ru/assets/courseware/v1/67aff42fc790c8a2282dc4b33f19a490/asset-v1:Skillfactory+DST-9+11DEC2019+type@asset+block/20573_Clipboard10_122_1113lo.jpg)

### Данные для создания модели

Организаторами соревнования предоставлен транировочный датасет, состоящий из датасета на 6682 записей , а также набора фотографий авто. В датасете представлено три марки авто: Mercedes, BMW и Audi.

Предсказать цену предлагается на тестовом датасете состоящем из 1671 записи.

### Цели и задачи проекта

#### Цели проекта (к чему будем стремиться): 
1. Научиться работать с нейросетевыми моделями для обработки табличных данных.
2. Научиться обрабатывать текстовые данные и оптимизировать NLP-модели.
3. Пройти весь цикл разработки Multi-Inputs моделей.
4. Показать максимально возможный результат для задачи регрессии (метрика "MAPE") в соревновании на Kaggle.

#### Задачи проекта (что в идеале хотелось бы сделать):
1. Улучшить результат baseline-решения по метрике "MAPE".
2. Провести предобработку данных (дубликаты, пропуски, выбросы).
3. Провести feature-engineering (отбор существующих признаков, синтез новых признаков, нормализация или стандартизация числовых признаков, кодирование категориальных признаков).
4. Применение стандартных NLP-архитектур, предобработки текста (аугментация, лемматизация), transfer-learning и fine-tuning для NLP, продвинутых архитектуры (SOTA) для NLP.
5. Применение станадартных архитектур для обраюотки изображений, дополнительных методов предобработки (аугментация), transfer-learning, fine-tuning и LR-Cycle, продвинутых архитектуры (SOTA) для NLP.
6. Анализ результатов раюоты модели (применение основных методов оценки ошибки обучения, нахождение оптимальных параметров обучения, выявление переобучения моделей)

### Итоги и выводы

Сcылка на мой Kaggle Kernel c лучшим резульататом:

https://www.kaggle.com/testdriver87/rds-06-by-petr-skokov-var5-cat-mlp
https://www.kaggle.com/testdriver87/rds-06-by-petr-skokov-var4-cat-mlp-nlp

Для начала 

[x] Лучший результат в совреновании на Kaggle в данный момент 11.70904 (9-ый из 23-х).

[x] Лучший результат в совреновании на Kaggle в данный момент 11.70904 (9-ый из 23-х).


Что можно сказать по итогам? 
 
