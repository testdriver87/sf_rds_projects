## RDS 06: Возьмёте Бэтмобиль?

Построение модели классификации изображений и участие в соответствующем [соревновании на Kaggle](https://www.kaggle.com/c/sf-dst-car-price-prediction-part2/ "соревновании на Kaggle")

![](https://lms.skillfactory.ru/assets/courseware/v1/67aff42fc790c8a2282dc4b33f19a490/asset-v1:Skillfactory+DST-9+11DEC2019+type@asset+block/20573_Clipboard10_122_1113lo.jpg)

### Данные для создания модели

Организаторами соревнования предоставлен транировочный датасет, состоящий из датасета на 6682 записей , а также набора фотографий авто. В датасете представлено три марки авто: Mercedes, BMW и Audi.

Предсказать цену предлагается на тестовом датасете состоящем из 1671 записи.

### Цели и задачи проекта

#### Цели проекта (к чему будем стремиться): 
1. Научиться работать с нейросетевыми моделями для обработки табличных данных.
2. Научиться обрабатывать текстовые данные и оптимизировать NLP-модели.
3. Пройти весь цикл разработки Multi-Inputs моделей.
4. Показать максимально возможный результат для задачи регрессии (метрика "MAPE") в соревновании на Kaggle.

#### Задачи проекта (что в идеале хотелось бы сделать):
1. Улучшить результат baseline-решения по метрике "MAPE".
2. Провести предобработку данных (дубликаты, пропуски, выбросы).
3. Провести feature-engineering (отбор существующих признаков, синтез новых признаков, нормализация или стандартизация числовых признаков, кодирование категориальных признаков).
4. Применение стандартных NLP-архитектур, предобработки текста (аугментация, лемматизация), transfer-learning и fine-tuning для NLP, продвинутых архитектуры (SOTA) для NLP.
5. Применение станадартных архитектур для обработки изображений, дополнительных методов предобработки (аугментация), transfer-learning, fine-tuning и Cycle LR, продвинутых архитектуры (SOTA) для NLP.
6. Анализ результатов работы модели (применение основных методов оценки ошибки обучения, нахождение оптимальных параметров обучения, выявление переобучения моделей)

### Итоги и выводы

Сcылка на мой Kaggle Kernel c лучшим резульататом:

https://www.kaggle.com/testdriver87/rds-06-by-petr-skokov-var5-cat-mlp

https://www.kaggle.com/testdriver87/rds-06-by-petr-skokov-var4-cat-mlp-nlp


Для начала немного о ходе работы над проектом. Досчитав до конца бэйслайн, мне стало очевидно, что часть Multi-Inputs нейросети, которая отвечает за обработку изображений только ухудшает целевую метрику. Конечно, возможно улучшить эту часть нейросети, применив, к примеру, модель EfficientNetB5 + продвинутые аугментации + Cycle LR, но это потребовало бы гораздо больше времени и не факт, что сильно улучшило бы метрику. Так как в прошлом проекте мы достаточно хорошо изучили эти техники, то было решено пока отбросить эту часть нейросети. Далее был проведен EDA-анализ (в репозитории отчет Pandas Profiling Report.html), переработано несколько старых признаков, синтезировано несколько новых признаков. Затем был получен сабмит на одиночной CatBoost-модели и дописан сабмит на основе кросс-валидации для CatBoost. Следующим шагом была немного модифицирована нейросеть для табличных данных, и получены сабмиты как на одиночной модели, так и на кросс-валидационной. Затем были обработаны текстовые данные из признака description, и оптимизирована NLP-модель. Я честно пытался объединить предсказания от CatBoost и нейросетей:) (даже использовал весовые коэффициенты при суммировании сабмишшенов от CatBoost и нейросетевой модели). Но в итоге самой лучшей оказалась нейросетевая модель для табличных данных на кросс-валидации. 


[x] Лучший результат в совреновании на Kaggle в данный момент 11.70904 (9-ый из 23-х).

[x] Дубликатов данных не было, пропуски устранены (в признаке "Владение" пропуски заменены на медианное значение по марке).

[x] Произведен отбор признаков, сгенерированы новые признаки, сокращена размерность. Применение логарифмирования и QuantileTransformer к числовым признакам и целевой переменной только ухудшало итоговую метрику поэтому от нее я отказался. Применена нормализация числовых признаков. Категориальные признаки сначала закодированы LabelEncoder, а затем OneHotEncoder. ПС. Бессмысленно выделять тот же XDrive или Quattro в отдельный признак, так как это всего лишь показатель наличия полного привода. Т.е. они будут коорелироваться с признаком "Привод".

[x] Применена стандартная архитектура для NLP-модели. Применена библиотека nltk для замены часто повторяющихся предложений на кодовое слово, для удаления стоп-слов. Применена лемматизация с помощью библиотеки pymorphy2. К сожалению, не было найдено натренированных SOTA моделей для русского языка для применения transfer learning.


Подводя итог, можно сделать вывод о том, что кросс-валидация на быстрой табличной нейростевой модели позволяет гораздо быстрее добиться нужного результата, чем работа с текстовыми и тем более графическими данными. Ну и блендинг предсказаний от модели грандиентного бустинга и нейросети имеет право на существование, так как это идеологически совершенно разные модели.
